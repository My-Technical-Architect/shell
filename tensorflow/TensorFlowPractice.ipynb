{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习介绍\n",
    "\n",
    "## 深度学习／机器学习／人工智能\n",
    "\n",
    "\n",
    "## 深度学习发展历程\n",
    "\n",
    "## 深度学习的应用\n",
    "\n",
    "## 深度学习的工具\n",
    "\n",
    "\n",
    "\n",
    "# TensorFlow环境搭建\n",
    "\n",
    "## 依赖包\n",
    "\n",
    "- Protocol Buffer\n",
    "\n",
    "- Bazel\n",
    "\n",
    "## install\n",
    "\n",
    "### docker安装\n",
    "\n",
    "\n",
    "### pip安装\n",
    "\n",
    "\n",
    "### 源码安装\n",
    "\n",
    "\n",
    "#### mac环境下安装\n",
    "\n",
    "```sh\n",
    "brew install bazel swig\n",
    "\n",
    "git clone https://github.com/tensorflow/tensorflow.git -b r0.9\n",
    "\n",
    "cd tensorflow\n",
    "./configure\n",
    "Please specify the location of python. [Default is /data/env/bin/python]:\n",
    "Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N\n",
    "No Google Cloud Platform support will be enabled for TensorFlow\n",
    "Do you wish to build TensorFlow with GPU support? [y/N] N\n",
    "No GPU support will be enabled for TensorFlow\n",
    "Configuration finished\n",
    "\n",
    "bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n",
    "./bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/work5/tensorflow/tensorflow_pkg\n",
    "pip install ~/work5/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl\n",
    "\n",
    "# 验证\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# r0.9编译遇到的问题\n",
    "# 1. tensorflow.bzl name 'DATA_CFG' is not defined\n",
    "# https://github.com/tensorflow/tensorflow/commit/7bcdcbbf60fc08346fd8016270a0563f4b51362b\n",
    "#  tensorflow/tensorflow.bzl \n",
    "# cfg = DATA_CFG 修改为 cfg = \"data\" \n",
    "# cfg = HOST_CFG 修改为 cfg = \"host\"\n",
    "\n",
    "\n",
    "# 2. depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set\n",
    "# https://github.com/tensorflow/tensorflow/pull/5144/files\n",
    "\n",
    "# py_test(\n",
    "#      name = \"session_test\",\n",
    "#      size = \"small\",\n",
    "#      srcs = [\"client/session_test.py\"],\n",
    "#      srcs_version = \"PY2AND3\",\n",
    "#      deps = [\n",
    "#          \":array_ops\",\n",
    "# +        \":construction_fails_op\",\n",
    "#          \":control_flow_ops\",\n",
    "#          \":data_flow_ops\",\n",
    "#          \":framework\",# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "#      srcs = [\"client/tf_session_helper.cc\"],\n",
    "#      hdrs = [\"client/tf_session_helper.h\"],\n",
    "#      deps = [\n",
    "# -        \":construction_fails_op\",\n",
    "#          \":numpy_lib\",\n",
    "# -        \":test_ops_kernels\",\n",
    "#          \"//tensorflow/c:c_api\",\n",
    "#          \"//tensorflow/c:tf_status_helper\",\n",
    "#          \"//tensorflow/core\",\n",
    "# @@ -1927,26 +1925,27 @@\n",
    "#      ],\n",
    "# )\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### centos 7 环境下安装\n",
    "```sh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow 安装验证\n",
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name = \"a\")\n",
    "b = tf.constant([2.0, 3.0], name = \"b\")\n",
    "result = a + b\n",
    "sess = tf.Session()\n",
    "sess.run(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "# TensorFlow基本概念模型\n",
    "\n",
    "## 概念\n",
    "\n",
    "### TensorFlow模型概念\n",
    "\n",
    "#### 计算模型---计算图\n",
    "\n",
    "- 计算图每个节点都是一个运算\n",
    "- 计算图上的边表示了运算之间的数据传递关系\n",
    "- 计算图上保存了每个运算的设备信息（CPU／GPU）\n",
    "- 计算图保存依赖关系\n",
    "- 计算图提供管理不同集合的功能，TensorFlow自动维护5个不同的默认集合\n",
    "- 隔离张量和计算（不同图上的张量和运算都不会共享）\n",
    "\n",
    "\n",
    "#### 数据模型---张量\n",
    "\n",
    "- 对中间结果引用\n",
    "- 获取计算结果\n",
    "- 张量本身不存储任何数据，只是对运算结果的引用\n",
    "- 张量结构\n",
    "\n",
    "> 三个属性： name（名字），shape（维度），type（类型）\n",
    "\n",
    "\n",
    "#### 运行模型---会话\n",
    "\n",
    "- 管理一个TensorFlow程序拥有的系统资源\n",
    "- 所有的运算都通过会话执行\n",
    "\n",
    "------\n",
    "\n",
    "###  其他概念\n",
    "\n",
    "- 全链接： 神经网络相邻两层之间任意两个节点之间都有连接\n",
    "- 隐藏层： 在输入和输出之间的神经网络叫做隐藏层\n",
    "\n",
    "- 监督学习最重要的思想： 在已知答案的标注数据集上，通过神经网络中的参数对训练数据进行拟合，可以得到模型对未知样本提供预测能力。\n",
    "\n",
    "\n",
    "## 前向传播算法简介\n",
    "\n",
    "### 神经网络前向传播结果需要3部分信息\n",
    "\n",
    "- 神经网络的输入： 即使从实体中提取特征向量\n",
    "- 神经网络的连接结构： 不同神经元（节点）之间输入输出的连接关系\n",
    "- 每个神经元中的参数\n",
    "\n",
    "\n",
    "## 训练神经网络过程的三个步骤\n",
    "\n",
    "- 定义神经网络的结构和前向传播的输出结果\n",
    "- 定义损失函数以及选择反向传播优化的算法\n",
    "- 生成会话，并且在训练数据上反复运行反向传播算法\n",
    "\n",
    "\n",
    "## TensorFlow游乐场\n",
    "\n",
    "http://playground.tensorflow.org/\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "# 深层神经网络\n",
    "## 深度学习与深层神经网络\n",
    "\n",
    "- 深度学习： 一类通过多层非线性变换对高复杂性数据建模算法的集合\n",
    "\n",
    "### 线性模型的局限性及解决\n",
    "\n",
    "#### 线性局限性---激活函数\n",
    "- 线性模型的最大特点就是，任意的线形组合仍然是线性模型。比如，当模型的输入只有一个输入的时候，x和y从城了二维坐标系的一条直线；当有n个输入的时候，x和y形成了n+1维空间的一个平面。\n",
    "- 局限性：线性模型的特点决定了只通过线性变换，任意层的全链接神经网络和单层神经网络的表达能力没有任何区别。而且它们都是线性模型，而线性模型能够解决的问题是有限的，这就是线性模型的最大局限性\n",
    "- 激活函数：relu，sigmoid，tanh等\n",
    "\n",
    "#### 异或运算局限性---隐藏层\n",
    "- 感知机模型： 单层的神经网络---先将输入进行加权求和，然后通过激活函数最后得到输出，即没有隐藏层的神经网络结构。\n",
    "- 深层神经网络： 加入隐藏层后，异或问题得到解决。\n",
    "\n",
    "\n",
    "## 损失函数---神经网络优化目标和神经网络模型效果\n",
    "\n",
    "### 交叉熵---分类问题损失函数\n",
    "\n",
    "- 交叉熵： 刻画两个概率分布之间的距离。神经网络通过softmax回归的神经网络，将神经网络输出变成一个概率分布。\n",
    "\n",
    "> 假设原始的神经网络输出为y1, y2,..., yn，那么经过softmax回归处理后的输出结果为：\n",
    "\n",
    "> $$ softmax(y)_i = y_i{}' = \\frac{e^{yi}}{\\sum_{j=1}^{n}e^{yi}}$$\n",
    "\n",
    "> 通过q来表示p的交叉熵为： $$H(p, q) =\\sum p(x)log q(x)$$\n",
    "\n",
    "> 它刻画了通过概率分布q来表达概率分布p的困难程度。当交叉熵作为神经网络的损失函数，p代表的是正确答案，q代表的是预测值。交叉熵刻画了两个概率的分布距离，即，交叉熵值越小，两个概率分布越接近。\n",
    "\n",
    "\n",
    "### 均方误差（MSE，mean squared error）--- 回归问题\n",
    "\n",
    "- 回归问题是对具体数值做预测，比如房价预测，销量预测等，即预测的不是一个事先定义好的类别，而是一个任意的实数。\n",
    "\n",
    "> MSE 定义如下\n",
    "$$MSE(y, y{}') = \\frac{\\sum_{j=1}^{n}(y_i-y_i{}')}{n}$$\n",
    "\n",
    "\n",
    "### 自定义损失函数\n",
    "\n",
    "\n",
    "\n",
    "## 神经网络优化算法---反向传播算法\n",
    "\n",
    "\n",
    "\n",
    "### 反向传播算法的优化过程\n",
    "\n",
    "- 反向传播算法以高效的方式在所有的参数上使用梯度下降算法，从而使神经网络训练模型在训数据上的损失函数尽可能的小。神经网络模型中参数的优化过程直接决定了模型的质量。\n",
    "\n",
    "- 神经网络的优化过程可以分为两个阶段：(TODO 数学推导后续再研究)\n",
    "\n",
    "> 1. 先通过前向传播算法计算得到预测值，并将预测值和真实值之间做对比得出两者的差距\n",
    "> 2. 通过反向传播算法计算损失函数对每一个参数的梯度，再根据梯度和学习率使用梯度下降算法更新每一个参数。\n",
    "\n",
    "#### 1. 梯度下降算法\n",
    "- 梯度下降算法主要用于优化单个参数的取值。计算公式为\n",
    "> $$ \\theta_{n+1} = \\theta_n - \\eta\\frac{\\partial }{\\partial \\theta_n} J(\\theta) $$\n",
    "> $$\\theta : 神经网络中的参数 $$\n",
    "> $$ J(\\theta) : 在给定的参数下，训练数据集上损失函数大小， 整个的优化过程可以抽象寻找一个参数 \\theta， 使得J(\\theta)最小$$\n",
    "> $$\\eta： 为学习率$$\n",
    "\n",
    "- 梯度下降算法的局限\n",
    "\n",
    "> 1. 梯度下降算法不能保证全局最优. 参数的初始值在很大程度影响最后得到的结果\n",
    "\n",
    "> 2. 计算时间过长。因为要在全部训练数据上最小化损失，所以损失函数是在所有训练数据上的损失和，这样在每一轮迭代中需要计算在全部训练数据上的损失函数，海量数据上会使训练时间过长。\n",
    "\n",
    "- 避免梯度下降算法局限的方式\n",
    "\n",
    "> 1. 损失函数为凸函数时，参数的初始值会很大程度影响是否能够找到全局最优解。 只有当损失函数为凸函数时，梯度下降算法才能够保证达到全局最优解。\n",
    "\n",
    "> 2. 使用随机梯度下降算法加速训练过程。问题：使用随机梯度下降优化算法得到的神经网络可能无法达到全局最优。 原因： 随机梯度下降算法不是在全部训练数据上的损失函数，而是在每一轮迭代过程中，随机优化某一条训练数据上的损失函数，这将会导致在某一条数据上损失函数更小，不能代表在全部数据上的损失函数更小。\n",
    "\n",
    "> 3. 实际处理方式： 每次计算batch（小部分）训练数据的损失函数。 通过矩阵运算，每次在一个batch上优化神经网络的参数并不会比单个数据慢太多；每一次使用一个batch可以大大减小收敛的迭代次数。 同时，也能够使收敛的结果更加接近梯度下降的效果。\n",
    "\n",
    "\n",
    "\n",
    "#### 2. 学习率优化\n",
    "\n",
    "- 学习率设置存在的问题\n",
    "\n",
    "> 1. 学习率过大： 导致参数在极优值的两侧来回移动\n",
    "> 2. 学习率过小： 能够保证收敛，但会大大降低优化速度\n",
    "\n",
    "- tensorflow设置学习率的方式\n",
    "\n",
    "> 1. 通过指数衰减的方法设置梯度下降算法中的学习率。既可以使模型在训练前期快速接近较优解，又可以保证模型在训练后期不会有很大的波动，从而更加接近局部最优\n",
    "\n",
    "> 2. tf.train.exponential_decay 函数实现了下面代码的功能：\n",
    "> decayed_learning_rate = learning_rate * decay_rate^(global_step/decay_steps)\n",
    "\n",
    "\n",
    "#### 3. 正则化优化--- 解决过拟合\n",
    "\n",
    "- 过拟合： 当模型过为复杂后，它可以很好的“记忆”每个训练数据中的随机噪音部分， 而没有“学习”训练数据中的通用趋势。\n",
    "\n",
    "- 正则化的思想： 在损失函数中加入刻画模型复杂度的指标。\n",
    "\n",
    "> 1. $$正则化的优化目标：不是直接的J(\\theta)， 而是最优J(\\theta) + \\lambda R(w)。 其中 \\lambda 表示模型复杂损失在总损失中的比例，$$\n",
    "> $$ \\theta 表示神经网络中的所有参数，包括边上的权重w和偏置项b， 一半来说模型复杂度只有权重w决定, R(w)刻画模型复杂度$$\n",
    "\n",
    "> 2. $$L1 正则化公式：R(w) = \\parallel w\\parallel_1 = \\sum_i\\mid w_i \\mid $$\n",
    "> $$L1 正则化公式：R(w) = \\parallel w\\parallel_2^2 = \\sum_i\\mid w_i^2 \\mid$$\n",
    "> $$在实践中可以将L1和L2同时使用：R(w) = \\sum_i \\alpha \\mid w_i \\mid + (1 - \\alpha) w_i^2 $$\n",
    "\n",
    "> 3. L1和L2的区别： （1）L1 正则会让参数变得更稀疏，而L2不会。 特征稀疏指的是会有更的参数变为0，这样可以达到类似特征选取的功能。L2不会让参数变的稀疏的原因是当参数很小了，比如0.001，这个参数的平方基本可以忽略了，于是模型不会进一步将这个参数调整为0\n",
    "\n",
    "> (2) L1公式不可导，L2可以。因为在优化时需要计算损失函数的偏导数，所以对含有L2正则化损失函数的优化更加简洁，而优化带L1正则化的损失函数会更佳复杂，而且优化方法也有很多种\n",
    "\n",
    "#### 4. 滑动平均模型\n",
    "\n",
    "- 滑动平均模型可以使模型在测试数据上更健壮的一种方法。\n",
    "\n",
    "- 在TensorFlow中使用tf.train.ExponentialMovingAverage实现滑动平均模型。在初始化ExponentialMovingAverate时，需要提供一个衰减率(decay)用来控制模型更新的速度。\n",
    "\n",
    "> ExponentialMovingAverage对每一个变量会维护一个影子变量，每次运行变量更新时，影子变量的值会更新为：\n",
    "> shadow_variable = decay * shadow_variable + (1 - decay) * variable, 其中decay为衰减率，会设置成更接近1的数，比如0.999, 0.9999，variable为待更新的变量，shadow_variable为影子变量。\n",
    "\n",
    "\n",
    "> $$ ExponentialMovingAverage使用num_updates参数动态设置decay大小。 decay = \\left \\{ decay,  \\frac{1 + numupdates}{10 + numupdates} \\right \\}$$\n",
    "\n",
    "\n",
    "\n",
    "## 神经网络优化中遇到的常见问题\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 其他学习资料\n",
    "\n",
    "http://www.deeplearningbook.org/ （Deep Learning An MIT Press book）\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/index.html （Ian Goodfellow, Yoshua Bengio, and Aaron Courville.）\n",
    "\n",
    "https://github.com/caicloud/tensorflow-tutorial.git (tensorflow 实战Google深度学习框架源码地址)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
